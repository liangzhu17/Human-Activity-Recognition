# -*- coding: utf-8 -*-
"""train_base_bayes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W0g3mbLbnLyPwggqEMiJIB-TW8_TjA7I
"""

!pip3 install tensorflow-gpu==2.0.0-beta0

!pip3 install bayesian-optimization

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf

import matplotlib.pyplot as plt
import os
from bayes_opt import BayesianOptimization
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.datasets import imdb
from keras.layers import Dense, Embedding, Dropout, LSTM
from keras.models import Sequential
from keras.optimizers import adam
from keras.preprocessing import sequence

import tensorflow as tf

import os
import glob
import numpy as np
import numpy.random as npr
import pandas as pd
import tensorflow.keras as k
import tensorflow.keras.layers as l
from tensorflow.keras.layers import Dense, Flatten, Conv2D
from tensorflow.keras import Model
import matplotlib.pyplot as plt
import random
from keras import optimizers
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_validate
from sklearn.model_selection import cross_val_score
from bayes_opt import BayesianOptimization
from keras.callbacks import ModelCheckpoint
from keras.optimizers import adam
from keras.models import Sequential
from keras.layers import Dense, Embedding, Dropout, LSTM

# read the csv files
train_x = pd.read_csv('/content/drive/My Drive/Masterlab/csv files/train_x.csv',skiprows=1,usecols=range(1,7),sep=',',header=None)
train_y = pd.read_csv('/content/drive/My Drive/Masterlab/csv files/train_y.csv',skiprows=1,usecols=range(1,13),sep=',',header=None)
val_x = pd.read_csv('/content/drive/My Drive/Masterlab/csv files/val_x.csv',skiprows=1,usecols=range(1,7),sep=',',header=None)
val_y = pd.read_csv('/content/drive/My Drive/Masterlab/csv files/val_y.csv',skiprows=1,usecols=range(1,13),sep=',',header=None)
test_x = pd.read_csv('/content/drive/My Drive/Masterlab/csv files/test_x.csv',skiprows=1,usecols=range(1,7),sep=',',header=None)
test_y = pd.read_csv('/content/drive/My Drive/Masterlab/csv files/test_y.csv',skiprows=1,usecols=range(1,13),sep=',',header=None)


# check the dimmesion of the above arrays
print(np.array(train_x).shape) 
print(np.array(train_y).shape)  # (469194, 12)
print(np.array(val_x).shape) 
print(np.array(val_y).shape)    # (133831, 12)
print(np.array(test_x).shape)   # (69910, 6)
print(np.array(test_y).shape)   # (69910, 12)
print(test_y.shape[0])

window_size = 500
window_shift = 250
batch_size = 80
epoch = 10

train_x = tf.convert_to_tensor(train_x.values)
train_y = tf.convert_to_tensor(train_y.values, dtype=tf.int16)
val_x = tf.convert_to_tensor(val_x.values)
val_y = tf.convert_to_tensor(val_y.values, dtype=tf.int16)
test_x = tf.convert_to_tensor(test_x.values)
test_y = tf.convert_to_tensor(test_y.values, dtype=tf.int16)


# sliding windows to create sequences
def sliding_win(x, y, window_size, window_shift, batch_size):
    
    ds_x = tf.data.Dataset.from_tensor_slices(x)
    ds_y = tf.data.Dataset.from_tensor_slices(y)
    
    ds_x = ds_x.window(size=window_size, shift=window_shift, drop_remainder=True).flat_map(
        lambda x: x.batch(window_size)).batch(batch_size, drop_remainder=True)
    ds_y = ds_y.window(size=window_size, shift=window_shift, drop_remainder=True).flat_map(
        lambda y: y.batch(window_size)).batch(batch_size, drop_remainder=True)
    ds = tf.data.Dataset.zip((ds_x, ds_y))
    return ds


# Dataset contains sequences pairs
train_sw = sliding_win(train_x,train_y, window_size, window_shift, batch_size)  
test_sw = sliding_win(test_x,test_y, window_size, window_shift, batch_size)
val_sw = sliding_win(val_x,val_y, window_size, window_shift, batch_size)

# build model 
# windows 500,250 optional

def base_model(dropout_, lstm_units_, fc_hidden_):
    inputs = tf.keras.layers.Input(shape=(window_size, 6))

    output = tf.keras.layers.LSTM(units=lstm_units_, return_sequences=True)(inputs)
    output = tf.keras.layers.Dropout(rate=dropout_)(output)

    output = tf.keras.layers.LSTM(units=lstm_units_, return_sequences=True)(output)
    output = tf.keras.layers.Dense(units=fc_hidden_, activation='relu')(output)   
    output = tf.keras.layers.Dropout(rate=dropout_)(output)

    output = tf.keras.layers.Dense(units=12, activation='softmax')(output)
    model = tf.keras.models.Model(inputs=inputs, outputs=output)

    return model


checkpoint_path = "test_ckpt/cp.ckpt"

#ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=model)
#manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=2)


# checkpoint_dir = os.path.dirname(checkpoint_path)
# Create a callback that saves the model's weights
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=1)
# model.save('my_model.h5',save_format="tf")

from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix
f = lambda x : x + 1

# test accuracy
def check_testing(mdl):
  l_arr = []
  p_arr = []
    
  for d,l in test_sw:  
    try:
        tf.enable_eager_execution()
    except Exception:
        pass
                                          # after unbatch   d(500,6)   l(500,12)
    if len(l_arr) == 0 and len(p_arr)==0:
      pred = mdl.predict(d)
      p = pred.reshape(-1,12)      # reduce dimension
      l = tf.reshape(l,(-1,12))    
      p_reformed = f(np.argmax(p, axis=1))       #(40000,)
      l_reformed = f(np.argmax(l, axis=1))       #(40000,)
      l_arr = l_reformed
      p_arr = p_reformed
    else:
      pred = mdl.predict(d)
      p = pred.reshape(-1,12)      # reduce dimension
      l = tf.reshape(l,(-1,12))
      p_reformed = f(np.argmax(p, axis=1))      
      l_reformed = f(np.argmax(l, axis=1))

      l_arr = np.hstack((l_arr, l_reformed))
      p_arr = np.hstack((p_arr, p_reformed))      #last (200000,)

  acc_score = accuracy_score(l_arr, p_arr)
  recall = recall_score(l_arr, p_arr, average="macro")
  precision = precision_score(l_arr, p_arr, average="macro")
  f1 = f1_score(l_arr, p_arr, average="macro")

  #return [acc_score, recall, precision, f1]
  return acc_score

def parameter_discrete(lstm_units, fc_hidden, dropout):
    lstm_units_disc = int(lstm_units)
    fc_hidden_disc = int(fc_hidden)
    dropout_disc = round(dropout,2)
    return lstm_units_disc, fc_hidden_disc, dropout_disc

from tensorflow.python.keras.optimizers import adam

def bayesian(train_sw, val_sw, dropout_=[0.0, 0.5], lstm_units_=[32,500], fc_hidden_=[32,256]):

  def train_mdl_evaluate(ds, lstm_units=32, fc_hidden=64, dropout=0.2, lr=3e-4, verbose=True):

    # discrete the hyperparameters
    lstm_units_disc, fc_hidden_disc, dropout_disc = parameter_discrete(lstm_units=32,fc_hidden=64,dropout=0.25)

    model = base_model(dropout_=dropout_disc, lstm_units_=lstm_units_disc, fc_hidden_=fc_hidden_disc)
    model.summary()
    model.compile(loss='categorical_crossentropy', optimizer=adam(lr), metrics=['acc'])
    history = model.fit(ds,epochs=4, validation_data=val_sw, steps_per_epoch=3,verbose=verbose, 
              callbacks=[cp_callback])

    model.save('my_model',save_format="tf")
    plot_history(history)
    
    acc = check_testing(model)
    return acc

  def plot_history(history):
    # summarize history for accuracy
    plt.plot(history.history['acc'], label='train_acc')
    plt.plot(history.history['val_acc'], label='val_acc')
    plt.title('model accuracy')
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.show()
    # summarize history for loss
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('model loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.show()


  model_dir = 'models'

  if not os.path.exists(model_dir):
    os.makedirs(model_dir)
  else: 
    pass
  # overfit_batch()

  optimizer = BayesianOptimization(
        f=train_mdl_evaluate(train_sw),
       
        pbounds={'lstm_units': (32, 500), 'fc_hidden': (32, 256), 'dropout': (0.0, 0.5)} 
        )

  optimizer.maximize(
        init_points=5,
        n_iter=30)
        #alpha=1e-3,
        #n_restarts_optimizer=5)

bayesian(train_sw,val_sw)

"""bds = [{'name': 'lstm_units', 'type': 'discrete', 'domain': (32, 500)},
        {'name': '', 'type': 'continuous', 'domain': (0, 5)},
        {'name': 'max_depth', 'type': 'discrete', 'domain': (1, 50)}"""

from bayes_opt import BayesianOptimization
import src.model.network as mdl
import gin
import src.visualization.logging as log

# Optimize will take arguments from the gin-config, where optimization bounds are defined
# It will read the training and validation dataset and based on them
# various neural networks will be evaluated
# n_iter: amount of iterations per defined bounds
# init_points: amount of random initialization for exploration
#
# Optimization objective: maximize sum of mean training accuracy and validation accuracy
# Optimizer: Bayesian optimization

# TODO: Remove mutual arguments -> source of all evil as I have read -> probably not good then :/
# TODO: SGD with learning rate


@gin.configurable
def optimize(train_ds, test_ds, val_ds, win_size=250, n_rnn_neurons=[10, 200],
             n_fcn_neurons=[10, 100], n_rnn_layer=[1, 1], n_fcn_layer=[1, 1],
             n_iter=4, init_points=2, dropout=[0, 0], logger=log.Logger(), s2s=True):

    def optimization_objective(n_rnn_n_, n_fcn_n_=1, n_rnn_l_=1, n_fcn_l_=1, dropout_=0):
        # Artifical discretization of optimization
        n_rnn_neurons_discrete = 2**int(n_rnn_n_)
        n_fcn_neurons_discrete = 2**int(n_fcn_n_)
        n_rnn_layer_discrete = int(n_rnn_l_)
        n_fcn_layer_discrete = int(n_fcn_l_)
        dropout_discrete = round(dropout_, 2)

        # Create network with current parameters
        network = mdl.Network(n_rnn_neurons=n_rnn_neurons_discrete, n_fcn_neurons=n_fcn_neurons_discrete,
                              rnn_layers=n_rnn_layer_discrete, fcn_layers=n_fcn_layer_discrete,
                              win_size=win_size, dropout=dropout_discrete, seq2seq=s2s)

        # Train network
        network.train(train_ds, test_ds=test_ds)

        # Evaluate network, optimization objective being the balanced accuracy
        # on the validation set
        if s2s:
            optimization_value = network.evaluate_custom(val_ds, 30)
        else:
            optimization_value = network.evaluate_custom_s2l(val_ds, 30)

        return optimization_value

    # Define bounds of parameter space
    # Must be defined in gin-config
    pbounds = {'n_rnn_n_': (n_rnn_neurons[0], n_rnn_neurons[1]), 'n_rnn_l_': (n_rnn_layer[0], n_rnn_layer[1]),
               'dropout_': (dropout[0], dropout[1])}

    # Create optimizer with given bounds and opimization objective
    optimizer = BayesianOptimization(f=optimization_objective,
                                     pbounds=pbounds,
                                     verbose=2,
                                     random_state=2)
    # Log bounds
    logger.log_file('Bounds: ' + str(pbounds))

    # And now optimize the hell out of it
    optimizer.maximize(init_points=init_points,
                       n_iter=n_iter)

    # Use given logger for saving results
    for iteration, result in enumerate(optimizer.res):
        logger.log_file('Iteration ' + str(iteration) + ': ' + str(result))
        logger.log_opt(step=iteration, name='target', value=result['target'])
        for parameter in result['params']:
            logger.log_opt(step=iteration, name=parameter,
                           value=round(result['params'][parameter], 2))

"""get ready for confusion matrix""""
def get_l_p():

  l_arr = []
  p_arr = []
    
  for d,l in test_sw:  
                                          # after unbatch   d(500,6)   l(500,12)
    if len(l_arr) == 0 and len(p_arr)==0:
      pred = model.predict(d)
      p = pred.reshape(-1,12)      # reduce dimension
      l = tf.reshape(l,(-1,12))    
      p_reformed = f(np.argmax(p, axis=1))       #(40000,)
      l_reformed = f(np.argmax(l, axis=1))       #(40000,)
      l_arr = l_reformed
      p_arr = p_reformed
    else:
      pred = model.predict(d)
      p = pred.reshape(-1,12)      # reduce dimension
      l = tf.reshape(l,(-1,12))
      p_reformed = f(np.argmax(p, axis=1))      
      l_reformed = f(np.argmax(l, axis=1))

      l_arr = np.hstack((l_arr, l_reformed))
      p_arr = np.hstack((p_arr, p_reformed))      #last (200000,)


  return l_arr, p_arr

# Metrics confusion matrix

def plot_confusion_matrix(cm, savename, title='Confusion Matrix'):
    plt.figure(figsize=(12, 8), dpi=100)
    np.set_printoptions(precision=2)

    # the probabilities in confusion matrix
    ind_array = np.arange(len(classes))
    x, y = np.meshgrid(ind_array, ind_array)
    for x_val, y_val in zip(x.flatten(), y.flatten()):
        c = cm[y_val][x_val]
        if c > 0.001:
            plt.text(x_val, y_val, "%0.2f" % (c,), color='red', fontsize=5, va='center', ha='center')

    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.binary)
    plt.title(title)
    plt.colorbar()
    xlocations = np.array(range(len(classes)))
    plt.xticks(xlocations, classes, rotation=90)
    plt.yticks(xlocations, classes)
    plt.ylabel('Actual label')
    plt.xlabel('Predict label')

    # offset the tick
    tick_marks = np.array(range(len(classes))) + 0.5
    plt.gca().set_xticks(tick_marks, minor=True)
    plt.gca().set_yticks(tick_marks, minor=True)
    plt.gca().xaxis.set_ticks_position('none')
    plt.gca().yaxis.set_ticks_position('none')
    plt.grid(True, which='minor', linestyle='-')
    plt.gcf().subplots_adjust(bottom=0.15)

    # show confusion matrix
    plt.savefig(savename, format='png')
    plt.show()


classes = ['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING', 'STAND_TO_SIT',
           'SIT_TO_STAND', 'SIT_TO_LIE', 'LIE_TO_SIT', 'STAND_TO_SIT', 'LIE_TO_STAND']

"""random_numbers = np.random.randint(6, size=50) [4 3 4 4 1 3 5 4 0 5 1 1 2 2 1 2 3 1 2 4 4 0 4 1 3 0 0 1 4 4 4 3 1 2 1 3 4
 4 0 2 0 5 5 4 2 0 3 2 1 2]
y_t = random_numbers.copy() 
random_numbers[:10] = np.random.randint(6, size=10)  # 将前10个样本的值进行随机更改 [0 4 5 1 0 5 0 2 0 1 1 1 2 2 1 2 3 1 2 4 4 0 4 1 3 0 0 1 4 4 4 3 1 2 1 3 4
 4 0 2 0 5 5 4 2 0 3 2 1 2]
y_p = random_numbers"""

y_true, y_pred = get_l_p()
print(np.array(y_true).shape)
print(np.array(y_pred).shape)
# 获取混淆矩阵
cm = confusion_matrix(y_true, y_pred)
plot_confusion_matrix(cm, 'confusion_matrix.png', title='confusion matrix')
"""if __name__ == '__main__':
    print()"""






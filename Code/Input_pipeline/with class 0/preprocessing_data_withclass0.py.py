# -*- coding: utf-8 -*-
"""preprocessing_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11d-7iM-PKNDDemDQxVbF5EAU7-29RFhg
"""

!pip3 install tensorflow-gpu==2.0.0-beta0

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
import os
import glob
import numpy as np
import numpy.random as npr
import pandas as pd
import tensorflow.keras as k
import tensorflow.keras.layers as l
from tensorflow.keras.layers import Dense, Flatten, Conv2D
from tensorflow.keras import Model
import matplotlib.pyplot as plt
import random
from keras import optimizers

# load filenames 

from glob import glob
# sort the HAPT data paths
raw_data_paths = sorted(glob("/content/drive/My Drive/Masterlab/RawData/*"))
print(raw_data_paths)

# Pipeline: Four steps.
"""1. The data and labels will be read and preprocessed, then saved in arrays with its experiment number as index
2. Data will be saved in array with its experiment number as index.
3. The Data will be combined togother in 3 whole matrix
4. Convert them to csv files"""

"""Read filenames"""
label_path = raw_data_paths[122]

window_size = 250
window_shift = 5
batch_size = 80
Epoch_num = 10


def read_file(filenames):
    # build np data 2D
    data = np.loadtxt(filenames)
    return data


# define a function to normalize the data, Z-Normalization
def preprocessing(data):
    result = (data - data.mean(axis=0)) / data.std(axis=0)
    return result


# Process the rawdata
def prepro_acc_gyro(raw_data, a, b):
    # acc data paths
    acc_file = raw_data[0:61]
    # gyro data paths
    gyro_file = raw_data[61:122]  # total 123 index from 0 to 122
    arr = []
    for i in range(a, b):
        acc = read_file(acc_file[i])
        gyro = read_file(gyro_file[i])
        acc_gyro = np.hstack((acc, gyro))  # Combine the 6 dimensions together
        
        acc_gyro_prep = preprocessing(acc_gyro)
        arr.append(acc_gyro_prep)
    return arr


"""The preprocessed data will be saved in a array. Index of the array is the number of experiments"""
input_arr = prepro_acc_gyro(raw_data_paths, 0, 61)
# print(input_arr[0].shape[0])  # (20598, 6)


label_file = read_file(label_path)

"""Get get the row numbers for each experiment in label.txt file. Example: row_num[0] to row_num[1] for experiment 1 user 1.""" 
def get_row_num():
    row_num = []
    j = 0
    for i in range(0, 62):  # for all the users und all experiments
        row_num.append(j)
        while j < 1214 and label_file[j][0] == i + 1:  # run for all experiments
            j = j + 1
    return row_num


row_num = get_row_num()
# print(row_num)
""""[0, 22, 45, 65, 85, 106, 126, 147, 167, 187, 207, 227, 247, 267, 287, 308, 329, 352, 372, 392, 404, 412, 433, 453, 
473, 493, 513, 533, 553, 573, 593, 613, 633, 653, 673, 693, 713, 733, 753, 773, 793, 813, 833, 853,
873, 894, 914, 934, 955, 975, 995, 1015, 1035, 1055, 1075, 1096, 1115, 1133, 1154, 1174, 1194, 1214]   num = 62
label_file row index"""


f = lambda x: x + 1

"""get the array of start_end_point for all experiments with help of array row_num[]. 
Example: 
start_end_arr[0] contains [[  250.  1232.] [ 1233.  1392.] [ 1393.  2194.] [ 2195.  2359.] [ 2360.  3374.]...]. 
All of the start end pairs are for experiment 1. """ 

def get_start_end_point():
    start_end_arr = []
    for i in range(0, 61):
        idx = row_num[i + 1]  # row numbers 60
        start_end = np.zeros((idx, 2))
        for j in range(row_num[i], row_num[i + 1]):
            start_end = label_file[row_num[i]:row_num[i + 1], 3:5]  # matrix idx x 3
        start_end_arr.append(start_end)

    return start_end_arr

start_end_arr = get_start_end_point()


"""The labels will be saved in a array "label_arr" with the same form of preprocessed data. Index of the array is the number of experiment """
"""The aim is to have all the input 6 dimension data and labels in same array form."""
# train____0:43, test_____43:55, val___55:61
# create the labels in array and translate them to one-hot coding
def build_label(data_arr, a, b):
    label_arr = []

    for i in range(a, b):  # (0,61)
        idx = data_arr[i].shape[0]
        label_list = np.zeros((idx, 12), np.int64)  # get the dimension of the input data

        for j in range(row_num[i], row_num[i + 1]):  # in every experiment exp_01,....
            start = label_file[j][3]
            end = label_file[j][4]
            for l in range(0, idx):
                class_num = int(label_file[j][2])
                if start <= l <= end:
                    if 1 <= class_num <= 12:
                        label_list[l, class_num - 1] = 1
        label_arr.append(label_list)

    return label_arr

label_arr = build_label(input_arr,0,61) 

# train 770774 test 233427 val 118571 sum 1122772


"""Since we already split the 3 datasets, the array index will be useless.
Last step is to traversal all the data from x_arr and y_arr together and combine them together. 
Without array index(experiment numbers), the 3 whole numpy matrix will be used to build dataset and to be trained easier. """

def build_input(in_arr, out_arr, a, b):
    for i in range(a, b):
        if i == a:
            in_matrix = in_arr[i]
            out_matrix = out_arr[i]
        else:
            in_matrix_added = in_arr[i]
            in_matrix = np.vstack((in_matrix, in_matrix_added))
            out_matrix_added = out_arr[i]
            out_matrix = np.vstack((out_matrix, out_matrix_added))

    return in_matrix, out_matrix


train_x, train_y = build_input(input_arr, label_arr, 0, 43)
val_x, val_y = build_input(input_arr, label_arr, 43, 55)
test_x, test_y = build_input(input_arr, label_arr, 55, 61)       


print("The dimension of train_x is :", np.array(train_x).shape)
print("The dimension of train_y is :", np.array(train_y).shape)
print("The dimension of test_x is :", np.array(test_x).shape)
print("The dimension of test_y is :", np.array(test_y).shape)
print("The dimension of val_x is :", np.array(val_x).shape)
print("The dimension of val_y is :", np.array(val_y).shape)

# concert them to csvfiles original data, with class 0 and class 1 to 12
pd.DataFrame(train_x).to_csv("/content/drive/My Drive/Masterlab/train_x.csv")
pd.DataFrame(train_y).to_csv("/content/drive/My Drive/Masterlab/train_y.csv")
pd.DataFrame(test_x).to_csv("/content/drive/My Drive/Masterlab/test_x.csv")
pd.DataFrame(test_y).to_csv("/content/drive/My Drive/Masterlab/test_y.csv")
pd.DataFrame(val_x).to_csv("/content/drive/My Drive/Masterlab/val_x.csv")
pd.DataFrame(val_y).to_csv("/content/drive/My Drive/Masterlab/val_y.csv")

# reading above csv files as numpy arrays and check dimmensions

my_train_x = pd.read_csv('/content/drive/My Drive/Masterlab/train_x.csv',skiprows=1,usecols=range(1,7),sep=',',header=None)
my_train_y = pd.read_csv('/content/drive/My Drive/Masterlab/train_y.csv',skiprows=1,usecols=range(1,13),sep=',',header=None)
my_val_x = pd.read_csv('/content/drive/My Drive/Masterlab/val_x.csv',skiprows=1,usecols=range(1,7),sep=',',header=None)
my_val_y = pd.read_csv('/content/drive/My Drive/Masterlab/val_y.csv',skiprows=1,usecols=range(1,13),sep=',',header=None)
my_test_x = pd.read_csv('/content/drive/My Drive/Masterlab/test_x.csv',skiprows=1,usecols=range(1,7),sep=',',header=None)
my_test_y = pd.read_csv('/content/drive/My Drive/Masterlab/test_y.csv',skiprows=1,usecols=range(1,13),sep=',',header=None)

print(np.array(my_train_x).shape) # (770775,7)  after (770774,6)
print(np.array(my_train_y).shape)
print(np.array(my_val_x).shape) # (233427, 6)
print(np.array(my_val_y).shape)
print(np.array(my_test_x).shape) # (118571, 6) 
print(np.array(my_test_y).shape)